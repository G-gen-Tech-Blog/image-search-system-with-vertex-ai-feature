{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "[公開用] vertex-ai-feature-store-get-embeddings.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gFiHK4palVw"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "! pip3 install --upgrade google-cloud-aiplatform \\\n",
        "                         google-cloud-bigquery\\\n",
        "                         google-cloud-storage\\\n",
        "                         bigframes\\\n",
        "                         pandas-gbq\\\n",
        "                         db-dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## セットアップ"
      ],
      "metadata": {
        "id": "MJRowUB7cDFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "7kGRd0Pfa5HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 環境変数を定義"
      ],
      "metadata": {
        "id": "kCrpWbkLcIov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BigQuery関連の設定\n",
        "PROJECT_ID = None  # @param {type:\"string\"} Google CloudプロジェクトID\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"} 使用するリージョン\n",
        "BQ_DATASET_ID = None  # @param {type:\"string\"} BigQueryのデータセットID\n",
        "BQ_TABLE_ID = None  # @param {type:\"string\"} BigQueryのテーブルID\n",
        "\n",
        "# Feature Storeの設定\n",
        "FEATURE_ONLINE_STORE_ID = None  # @param {type:\"string\"} Feature StoreのオンラインストアID\n",
        "FEATURE_VIEW_ID = None  # @param {type:\"string\"} Feature StoreのビューID\n",
        "\n",
        "# スケジュール設定\n",
        "# スケジュールはCRON設定に基づいて作成されます。\n",
        "# CRONが空の場合、即時スケジュールジョブが開始されます。\n",
        "CRON_SCHEDULE = \"TZ=Asia/Tokyo 0 8 * * *\"  # @param {type:\"string\"} スケジュール設定（東京時間で毎日午前9時）\n",
        "\n",
        "# ベクトル検索の設定\n",
        "DIMENSIONS = 768  # @param {type:\"number\"} ベクトルの次元数\n",
        "EMBEDDING_COLUMN = \"embedding\"  # @param {type:\"string\"} 埋め込みを保持する列名\n",
        "\n",
        "# オプショナル設定\n",
        "LEAF_NODE_EMBEDDING_COUNT = 10000  # @param {type:\"number\"} リーフノードの埋め込み数（オプショナル）\n",
        "FILTER_COLUMNS = [\"title\"]  # @param {type:\"string\"} フィルタリングに使用する列（オプショナル）\n"
      ],
      "metadata": {
        "id": "TsQaaenjbFpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ユーティリティ関数を定義"
      ],
      "metadata": {
        "id": "zo40lI6kb5Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Cloud AI Platform関連のインポート\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform_v1beta1 import (\n",
        "    FeatureOnlineStoreAdminServiceClient,\n",
        "    FeatureOnlineStoreServiceClient\n",
        ")\n",
        "from google.cloud.aiplatform_v1beta1.types import (\n",
        "    NearestNeighborQuery,\n",
        "    feature_online_store as feature_online_store_pb2,\n",
        "    feature_online_store_admin_service as feature_online_store_admin_service_pb2,\n",
        "    feature_online_store_service as feature_online_store_service_pb2,\n",
        "    feature_view as feature_view_pb2\n",
        ")\n",
        "from google.protobuf import struct_pb2\n",
        "from vertexai.language_models import TextEmbeddingModel\n",
        "\n",
        "# Google Cloud BigQuery関連のインポート\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Google Cloud Storage関連のインポート\n",
        "from google.cloud import storage\n",
        "\n",
        "# その他のインポート\n",
        "import bigframes.pandas as bpd\n",
        "import random\n",
        "import base64\n",
        "import time\n",
        "import typing\n",
        "\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\"\n",
        "\n",
        "admin_client = FeatureOnlineStoreAdminServiceClient(\n",
        "    client_options={\"api_endpoint\": API_ENDPOINT}\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Set BigQuery DataFrames options\n",
        "bpd.options.bigquery.project = PROJECT_ID\n",
        "bpd.options.bigquery.location = \"us\"\n",
        "\n",
        "def list_gcs_files(bucket_name, prefix):\n",
        "    \"\"\"Return a list of file names in the specified GCS bucket and prefix without the prefix.\"\"\"\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs(prefix=prefix)\n",
        "    # Remove the prefix from each file name\n",
        "    return [blob.name.replace(prefix, '') for blob in blobs]\n",
        "\n",
        "def list_files_from_metadata(metadata_paths):\n",
        "    \"\"\"Return a list of file names from the metadata txt files.\"\"\"\n",
        "    file_list = []\n",
        "    storage_client = storage.Client()\n",
        "\n",
        "    for metadata_path in metadata_paths:\n",
        "        bucket_name, file_path = metadata_path.split(\"gs://\")[1].split(\"/\", 1)\n",
        "        bucket = storage_client.bucket(bucket_name)\n",
        "        blob = bucket.blob(file_path)\n",
        "        content = blob.download_as_text()\n",
        "        # Convert each line to its corresponding image path with .jpg extension\n",
        "        file_list.extend([line + \".jpg\" for line in content.splitlines()])\n",
        "\n",
        "    return file_list\n",
        "\n",
        "def upload_to_gcs(local_file, bucket_name, gcs_path):\n",
        "    \"\"\"Upload a local file to GCS.\"\"\"\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(gcs_path)\n",
        "    blob.upload_from_filename(local_file)"
      ],
      "metadata": {
        "id": "A7u_yTkrbKQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import time\n",
        "import typing\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from google.protobuf import struct_pb2\n",
        "\n",
        "\n",
        "class EmbeddingResponse(typing.NamedTuple):\n",
        "    text_embedding: typing.Sequence[float]\n",
        "    image_embedding: typing.Sequence[float]\n",
        "\n",
        "\n",
        "def load_image_bytes(image_uri: str) -> bytes:\n",
        "    \"\"\"Load image bytes from a remote or local URI.\"\"\"\n",
        "    image_bytes = None\n",
        "    if image_uri.startswith(\"http://\") or image_uri.startswith(\"https://\"):\n",
        "        response = requests.get(image_uri, stream=True)\n",
        "        if response.status_code == 200:\n",
        "            image_bytes = response.content\n",
        "    else:\n",
        "        image_bytes = open(image_uri, \"rb\").read()\n",
        "    return image_bytes\n",
        "\n",
        "\n",
        "class EmbeddingPredictionClient:\n",
        "    \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        project: str,\n",
        "        location: str = \"us-central1\",\n",
        "        api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
        "    ):\n",
        "        client_options = {\"api_endpoint\": api_regional_endpoint}\n",
        "        # Initialize client that will be used to create and send requests.\n",
        "        # This client only needs to be created once, and can be reused for multiple requests.\n",
        "        self.client = aiplatform.gapic.PredictionServiceClient(\n",
        "            client_options=client_options\n",
        "        )\n",
        "        self.location = location\n",
        "        self.project = project\n",
        "\n",
        "    def get_embedding(self, text: str = None, image_file: str = None, model_name: str = \"multimodalembedding@001\"):\n",
        "        if not text and not image_file:\n",
        "            raise ValueError(\"At least one of text or image_file must be specified.\")\n",
        "\n",
        "        # Load image file\n",
        "        image_bytes = None\n",
        "        if image_file:\n",
        "            image_bytes = load_image_bytes(image_file)\n",
        "\n",
        "        instance = struct_pb2.Struct()\n",
        "        if text:\n",
        "            instance.fields[\"text\"].string_value = text\n",
        "\n",
        "        if image_bytes:\n",
        "            encoded_content = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "            image_struct = instance.fields[\"image\"].struct_value\n",
        "            image_struct.fields[\"bytesBase64Encoded\"].string_value = encoded_content\n",
        "\n",
        "        instances = [instance]\n",
        "\n",
        "        endpoint = (\n",
        "            f\"projects/{self.project}/locations/{self.location}/publishers/google/models/{model_name}\"\n",
        "        )\n",
        "\n",
        "        response = self.client.predict(endpoint=endpoint, instances=instances)\n",
        "        text_embedding = None\n",
        "\n",
        "        if text:\n",
        "            text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
        "            text_embedding = [v for v in text_emb_value]\n",
        "\n",
        "        image_embedding = None\n",
        "        if image_bytes:\n",
        "            image_emb_value = response.predictions[0][\"imageEmbedding\"]\n",
        "            image_embedding = [v for v in image_emb_value]\n",
        "\n",
        "        return EmbeddingResponse(\n",
        "            text_embedding=text_embedding, image_embedding=image_embedding\n",
        "        )\n",
        "\n",
        "    def get_embedding_text_model(self, text: str = None, model_name: str = \"textembedding-gecko@001\", task_type: str = \"RETRIEVAL_QUERY\"):\n",
        "        model = TextEmbeddingModel.from_pretrained(model_name)\n",
        "        embeddings = model.get_embeddings([text])\n",
        "        for embedding in embeddings:\n",
        "            vector = embedding.values\n",
        "            print(f\"Length of Embedding Vector: {len(vector)}\")\n",
        "        return EmbeddingResponse(\n",
        "            text_embedding=vector, image_embedding=None\n",
        "        )"
      ],
      "metadata": {
        "id": "FCSAgnSZbMkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from typing import List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "from tenacity import retry, stop_after_attempt\n",
        "\n",
        "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
        "\n",
        "\n",
        "# Use a retry handler in case of failure\n",
        "@retry(reraise=True, stop=stop_after_attempt(3))\n",
        "def encode_texts_to_embeddings_with_retry(text: List[str], model_name: str) -> List[List[float]]:\n",
        "    assert len(text) == 1\n",
        "\n",
        "    try:\n",
        "        return [client.get_embedding(text=text[0], image_file=None, model_name=model_name).text_embedding]\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\"Error getting embedding.\")\n",
        "\n",
        "# Use a retry handler in case of failure\n",
        "@retry(reraise=True, stop=stop_after_attempt(3))\n",
        "def encode_texts_to_text_model_embeddings_with_retry(text: List[str], model_name: str) -> List[List[float]]:\n",
        "    assert len(text) == 1\n",
        "\n",
        "    try:\n",
        "        return [client.get_embedding_text_model(text=text[0], model_name=model_name).text_embedding]\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\"Error getting embedding.\")\n",
        "\n",
        "def encode_texts_to_embeddings(text: List[str], model_name: str) -> List[Optional[List[float]]]:\n",
        "    try:\n",
        "        return encode_texts_to_embeddings_with_retry(text=text, model_name=model_name)\n",
        "    except Exception:\n",
        "        return [None for _ in range(len(text))]\n",
        "\n",
        "def encode_texts_to_text_model_embeddings(text: List[str], model_name: str) -> List[Optional[List[float]]]:\n",
        "    try:\n",
        "        return encode_texts_to_text_model_embeddings_with_retry(text=text, model_name=model_name)\n",
        "    except Exception:\n",
        "        return [None for _ in range(len(text))]\n",
        "\n",
        "\n",
        "@retry(reraise=True, stop=stop_after_attempt(3))\n",
        "def encode_images_to_embeddings_with_retry(image_uris: List[str], model_name: str) -> List[List[float]]:\n",
        "    assert len(image_uris) == 1\n",
        "\n",
        "    try:\n",
        "        return [\n",
        "            client.get_embedding(text=None, image_file=image_uris[0], model_name=model_name).image_embedding\n",
        "        ]\n",
        "    except Exception as ex:\n",
        "        raise RuntimeError(\"Error getting embedding.\")\n",
        "\n",
        "\n",
        "def encode_images_to_embeddings(image_uris: List[str], model_name: str) -> List[Optional[List[float]]]:\n",
        "    try:\n",
        "        return encode_images_to_embeddings_with_retry(image_uris=image_uris, model_name=model_name)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "        return [None for _ in range(len(image_uris))]"
      ],
      "metadata": {
        "id": "PkPB4q9xbhbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from typing import Callable, Generator, List\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def generate_batches(\n",
        "    inputs: List[str], batch_size: int\n",
        ") -> Generator[List[str], None, None]:\n",
        "    \"\"\"\n",
        "    Generator function that takes a list of strings and a batch size, and yields batches of the specified size.\n",
        "    \"\"\"\n",
        "\n",
        "    for i in range(0, len(inputs), batch_size):\n",
        "        yield inputs[i : i + batch_size]\n",
        "\n",
        "\n",
        "API_IMAGES_PER_SECOND = 2\n",
        "\n",
        "\n",
        "def encode_to_embeddings_chunked(\n",
        "    process_function: Callable[[List[str]], List[Optional[List[float]]]],\n",
        "    items: List[str],\n",
        "    model_name: str,\n",
        "    batch_size: int = 1,\n",
        ") -> List[Optional[List[float]]]:\n",
        "    \"\"\"\n",
        "    Function that encodes a list of strings into embeddings using a process function.\n",
        "    It takes a list of strings and returns a list of optional lists of floats.\n",
        "    The data is processed in chunks to prevent out-of-memory errors.\n",
        "    \"\"\"\n",
        "\n",
        "    embeddings_list: List[Optional[List[float]]] = []\n",
        "\n",
        "    # Prepare the batches using a generator\n",
        "    batches = generate_batches(items, batch_size)\n",
        "\n",
        "    seconds_per_job = batch_size / API_IMAGES_PER_SECOND\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for batch in tqdm(batches, total=len(items) // batch_size, position=0):\n",
        "            futures.append(executor.submit(process_function, batch, model_name))\n",
        "            time.sleep(seconds_per_job)\n",
        "\n",
        "        for future in futures:\n",
        "            embeddings_list.extend(future.result())\n",
        "    return embeddings_list"
      ],
      "metadata": {
        "id": "H_6bF5xKbt7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データ準備"
      ],
      "metadata": {
        "id": "nrXb-sHeceXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# エンベディング抽出対象画像をGCSに配置\n",
        "selected_paths = [\"chinsuko_3.jpg\",\n",
        " \"okinawa-soba-3.jpg\",\n",
        " \"umibudo_3.jpeg\"]\n",
        "\n",
        "# それぞれの商品画像の概要を定義\n",
        "descriptions = [\"ちんすこうは沖縄の伝統的な焼き菓子で、サクサクとした食感と優しい甘さが魅力です。主な材料は小麦粉、砂糖、ラードで、これらを練り合わせて焼き上げます。元々は王族や貴族のための菓子でしたが、今では沖縄のお土産として広く親しまれています。そのバリエーションは豊富で、プレーンタイプから、黒糖や塩、紅芋など様々なフレーバーが楽しめます。軽い食感と独特の風味が、お茶請けやおやつに最適です。\",\n",
        "                 \"沖縄そばは、日本の沖縄県独特の麺料理です。中太のちぢれた麺は小麦粉を主原料とし、コシがありつるつるとした食感が特徴です。通常、豚肉やかまぼこ、ネギといった具材がトッピングされ、煮込んだ豚の骨から取ったコクのあるスープで味わいます。沖縄そばは、そのシンプルながら深い味わいで、地元民はもちろんのこと観光客にも愛されています。伝統的な沖縄の食文化の一環として、多くの食堂や専門店で提供されています。\",\n",
        "                 \"海ぶどうは沖縄の海岸近くで育つ海藻の一種で、小さな透明な粒がブドウのように連なっていることからその名がつきました。プチプチとした食感と、海のミネラルを感じる独特の風味が特徴です。生で食べることが多く、ポン酢や醤油で味付けして楽しまれます。海ぶどうは、沖縄料理の中でも特に珍しい食材であり、観光客には新鮮な体験として人気があります。栄養価が高く、健康的な食品としても注目されています。\"]\n",
        "\n",
        "# 売上額を定義\n",
        "sales_amounts = [200000000, 1000000000, 100000000]\n",
        "\n",
        "# 売上数を定義\n",
        "number_of_sales_list = [133333, 1250000, 142857]"
      ],
      "metadata": {
        "id": "XmDX1t_BcgpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ベクトル抽出（画像から（マルチモーダル））"
      ],
      "metadata": {
        "id": "dFUjmt7XcSuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Encode a sample subset of images\n",
        "image_embeddings = encode_to_embeddings_chunked(\n",
        "    process_function=encode_images_to_embeddings, items=selected_paths, model_name=\"multimodalembedding@001\"\n",
        ")\n",
        "\n",
        "# Keep only non-None embeddings\n",
        "indexes_to_keep, image_embeddings = zip(\n",
        "    *[\n",
        "        (index, embedding)\n",
        "        for index, embedding in enumerate(image_embeddings)\n",
        "        if embedding is not None\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"Processed {len(indexes_to_keep)} embeddings successfully\")"
      ],
      "metadata": {
        "id": "shjl1Ix_byJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ベクトル抽出（文章から（マルチモーダル））"
      ],
      "metadata": {
        "id": "lF2yDE_-dD8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Encode a sample subset of images\n",
        "text_embeddings = encode_to_embeddings_chunked(\n",
        "    process_function=encode_texts_to_embeddings, items=descriptions, model_name=\"multimodalembedding@001\"\n",
        ")\n",
        "\n",
        "# Keep only non-None embeddings\n",
        "indexes_to_keep, text_embeddings = zip(\n",
        "    *[\n",
        "        (index, embedding)\n",
        "        for index, embedding in enumerate(text_embeddings)\n",
        "        if embedding is not None\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"Processed {len(indexes_to_keep)} embeddings successfully\")"
      ],
      "metadata": {
        "id": "3QTqxaZtdC-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ベクトル抽出（文章から（テキストエンベディング））"
      ],
      "metadata": {
        "id": "Rz1Wo0jBk-3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Encode a sample subset of images\n",
        "text_embeddings = encode_to_embeddings_chunked(\n",
        "    process_function=encode_texts_to_text_model_embeddings, items=descriptions, model_name=\"textembedding-gecko-multilingual@001\"\n",
        ")\n",
        "\n",
        "# text_embeddings\n",
        "# Keep only non-None embeddings\n",
        "indexes_to_keep, text_embeddings = zip(\n",
        "    *[\n",
        "        (index, embedding)\n",
        "        for index, embedding in enumerate(text_embeddings)\n",
        "        if embedding is not None\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"Processed {len(indexes_to_keep)} embeddings successfully\")"
      ],
      "metadata": {
        "id": "JrzKmYmLk79e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BigQuery にアップロード"
      ],
      "metadata": {
        "id": "wCGlr7Wedf57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas_gbq import to_gbq\n",
        "\n",
        "\n",
        "def extract_name(path):\n",
        "    return path.split('/')[-2]\n",
        "\n",
        "df = pd.DataFrame({'title': pd.Series(selected_paths).map(extract_name).tolist(),\n",
        "                   'embedding': text_embeddings, # テキストの場合\n",
        "                  #  'embedding': image_embeddings, # 画像の場合\n",
        "                   'image_path': selected_paths,\n",
        "                   'description': descriptions,\n",
        "                   'sales_amount': sales_amounts,\n",
        "                   'number_of_sales': number_of_sales_list})\n",
        "df"
      ],
      "metadata": {
        "id": "0gZZQdzxdUrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 書き込み先テーブル\n",
        "BQ_TABLE_ID_FQN = f\"{BQ_DATASET_ID}.{BQ_TABLE_ID}\"\n",
        "\n",
        "# スキーマを定義\n",
        "table_schema=[\n",
        "    {'name': 'title', 'type': 'STRING'},\n",
        "    {'name': 'embedding', 'type': 'FLOAT64', 'mode': 'REPEATED'},\n",
        "    {'name': 'image_path', 'type': 'STRING'},\n",
        "    {'name': 'description', 'type': 'STRING'},\n",
        "    {'name': 'sales_amount', 'type': 'INT64'},\n",
        "    {'name': 'number_of_sales', 'type': 'INT64'},\n",
        "]\n",
        "\n",
        "# ロード\n",
        "to_gbq(df, BQ_TABLE_ID_FQN, project_id=PROJECT_ID, if_exists='append', table_schema=table_schema)"
      ],
      "metadata": {
        "id": "QyBeMBmmdjrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 手動同期ジョブを実行\n",
        "\n",
        "BigQuery と オンラインストアを同期"
      ],
      "metadata": {
        "id": "6fxR1-2Ggkbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sync_response = admin_client.sync_feature_view(\n",
        "    feature_view=f\"projects/{PROJECT_ID}/locations/{REGION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}/featureViews/{FEATURE_VIEW_ID}\"\n",
        ")"
      ],
      "metadata": {
        "id": "qUAc9-qmf-bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "while True:\n",
        "    feature_view_sync = admin_client.get_feature_view_sync(\n",
        "        name=sync_response.feature_view_sync\n",
        "    )\n",
        "    if feature_view_sync.run_time.end_time.seconds > 0:\n",
        "        status = \"Succeed\" if feature_view_sync.final_status.code == 0 else \"Failed\"\n",
        "        print(f\"Sync {status} for {feature_view_sync.name}.\")\n",
        "        # wait a little more for the job to properly shutdown\n",
        "        time.sleep(30)\n",
        "        break\n",
        "    else:\n",
        "        print(\"Sync ongoing, waiting for 30 seconds.\")\n",
        "    time.sleep(30)"
      ],
      "metadata": {
        "id": "4gVxj6R0gpyX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}