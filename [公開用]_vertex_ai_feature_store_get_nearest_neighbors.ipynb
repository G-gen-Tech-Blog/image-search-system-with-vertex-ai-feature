{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "[公開用] vertex-ai-feature-store-get-nearest-neighbors.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKoDXfUFml6Z"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "! pip3 install --upgrade google-cloud-aiplatform \\\n",
        "                         google-cloud-bigquery\\\n",
        "                         google-cloud-storage\\\n",
        "                         bigframes\\\n",
        "                         pandas-gbq\\\n",
        "                         db-dtypes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "91Ravsknm1R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BigQuery関連の設定\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"} Google CloudプロジェクトID\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"} 使用するリージョン\n",
        "BQ_DATASET_ID = \"\"  # @param {type:\"string\"} BigQueryのデータセットID\n",
        "BQ_TABLE_ID = \"\"  # @param {type:\"string\"} BigQueryのテーブルID\n",
        "\n",
        "# Feature Storeの設定\n",
        "FEATURE_ONLINE_STORE_ID = \"\"  # @param {type:\"string\"} Feature StoreのオンラインストアID\n",
        "FEATURE_VIEW_ID = \"\"  # @param {type:\"string\"} Feature StoreのビューID\n",
        "\n",
        "# スケジュール設定\n",
        "# スケジュールはCRON設定に基づいて作成されます。\n",
        "# CRONが空の場合、即時スケジュールジョブが開始されます。\n",
        "CRON_SCHEDULE = \"TZ=Asia/Tokyo 0 9 * * *\"  # @param {type:\"string\"} スケジュール設定（東京時間で毎日午前9時）\n",
        "\n",
        "# ベクトル検索の設定\n",
        "DIMENSIONS = 1408  # @param {type:\"number\"} ベクトルの次元数\n",
        "EMBEDDING_COLUMN = \"embedding\"  # @param {type:\"string\"} 埋め込みを保持する列名\n",
        "\n",
        "# オプショナル設定\n",
        "LEAF_NODE_EMBEDDING_COUNT = 10000  # @param {type:\"number\"} リーフノードの埋め込み数（オプショナル）\n",
        "FILTER_COLUMNS = [\"title\"]  # @param {type:\"string\"} フィルタリングに使用する列（オプショナル）\n",
        "\n",
        "# Feature Store のデータソースとなる BigQuery テーブルを定義\n",
        "BQ_TABLE_ID_FQN = f\"{BQ_DATASET_ID}.{BQ_TABLE_ID}\"\n",
        "DATA_SOURCE = f\"bq://{PROJECT_ID}.{BQ_TABLE_ID_FQN}\"\n",
        "\n",
        "# オンラインストアのエンドポイント\n",
        "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\"\n",
        "\n",
        "# オンラインストアのパブリックエンドポイント\n",
        "PUBLIC_ENDPOINT=\"xxxxx-sample.vdb.vertexai.goog\" # @param {type:\"string\"}\n",
        "\n",
        "# 画像公開用 GCS のホストパス\n",
        "GCS_HOST_PATH = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "jpV1vuVUm9OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Cloud AI Platform関連のインポート\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform_v1beta1 import (\n",
        "    FeatureOnlineStoreAdminServiceClient,\n",
        "    FeatureOnlineStoreServiceClient\n",
        ")\n",
        "from google.cloud.aiplatform_v1beta1.types import (\n",
        "    NearestNeighborQuery,\n",
        "    feature_online_store as feature_online_store_pb2,\n",
        "    feature_online_store_admin_service as feature_online_store_admin_service_pb2,\n",
        "    feature_online_store_service as feature_online_store_service_pb2,\n",
        "    feature_view as feature_view_pb2\n",
        ")\n",
        "from google.protobuf import struct_pb2\n",
        "\n",
        "# Google Cloud BigQuery関連のインポート\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Google Cloud Storage関連のインポート\n",
        "from google.cloud import storage\n",
        "\n",
        "# その他のインポート\n",
        "import bigframes.pandas as bpd\n",
        "import random\n",
        "import base64\n",
        "import time\n",
        "import typing\n",
        "\n",
        "\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "admin_client = FeatureOnlineStoreAdminServiceClient(\n",
        "    client_options={\"api_endpoint\": API_ENDPOINT}\n",
        ")\n",
        "\n",
        "data_client = FeatureOnlineStoreServiceClient(\n",
        "    client_options={\"api_endpoint\": PUBLIC_ENDPOINT}\n",
        ")\n",
        "\n",
        "\n",
        "# Set BigQuery DataFrames options\n",
        "bpd.options.bigquery.project = PROJECT_ID\n",
        "bpd.options.bigquery.location = \"us\"\n",
        "\n",
        "def list_gcs_files(bucket_name, prefix):\n",
        "    \"\"\"Return a list of file names in the specified GCS bucket and prefix without the prefix.\"\"\"\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs(prefix=prefix)\n",
        "    # Remove the prefix from each file name\n",
        "    return [blob.name.replace(prefix, '') for blob in blobs]\n",
        "\n",
        "def list_files_from_metadata(metadata_paths):\n",
        "    \"\"\"Return a list of file names from the metadata txt files.\"\"\"\n",
        "    file_list = []\n",
        "    storage_client = storage.Client()\n",
        "\n",
        "    for metadata_path in metadata_paths:\n",
        "        bucket_name, file_path = metadata_path.split(\"gs://\")[1].split(\"/\", 1)\n",
        "        bucket = storage_client.bucket(bucket_name)\n",
        "        blob = bucket.blob(file_path)\n",
        "        content = blob.download_as_text()\n",
        "        # Convert each line to its corresponding image path with .jpg extension\n",
        "        file_list.extend([line + \".jpg\" for line in content.splitlines()])\n",
        "\n",
        "    return file_list\n",
        "\n",
        "def upload_to_gcs(local_file, bucket_name, gcs_path):\n",
        "    \"\"\"Upload a local file to GCS.\"\"\"\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(gcs_path)\n",
        "    blob.upload_from_filename(local_file)"
      ],
      "metadata": {
        "id": "huSmmK04nCh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import time\n",
        "import typing\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from google.protobuf import struct_pb2\n",
        "\n",
        "\n",
        "class EmbeddingResponse(typing.NamedTuple):\n",
        "    text_embedding: typing.Sequence[float]\n",
        "    image_embedding: typing.Sequence[float]\n",
        "\n",
        "\n",
        "def load_image_bytes(image_uri: str) -> bytes:\n",
        "    \"\"\"Load image bytes from a remote or local URI.\"\"\"\n",
        "    image_bytes = None\n",
        "    if image_uri.startswith(\"http://\") or image_uri.startswith(\"https://\"):\n",
        "        response = requests.get(image_uri, stream=True)\n",
        "        if response.status_code == 200:\n",
        "            image_bytes = response.content\n",
        "    else:\n",
        "        image_bytes = open(image_uri, \"rb\").read()\n",
        "    return image_bytes\n",
        "\n",
        "\n",
        "class EmbeddingPredictionClient:\n",
        "    \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        project: str,\n",
        "        location: str = \"us-central1\",\n",
        "        api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
        "    ):\n",
        "        client_options = {\"api_endpoint\": api_regional_endpoint}\n",
        "        # Initialize client that will be used to create and send requests.\n",
        "        # This client only needs to be created once, and can be reused for multiple requests.\n",
        "        self.client = aiplatform.gapic.PredictionServiceClient(\n",
        "            client_options=client_options\n",
        "        )\n",
        "        self.location = location\n",
        "        self.project = project\n",
        "\n",
        "    def get_embedding(self, text: str = None, image_file: str = None):\n",
        "        if not text and not image_file:\n",
        "            raise ValueError(\"At least one of text or image_file must be specified.\")\n",
        "\n",
        "        # Load image file\n",
        "        image_bytes = None\n",
        "        if image_file:\n",
        "            image_bytes = load_image_bytes(image_file)\n",
        "\n",
        "        instance = struct_pb2.Struct()\n",
        "        if text:\n",
        "            instance.fields[\"text\"].string_value = text\n",
        "\n",
        "        if image_bytes:\n",
        "            encoded_content = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "            image_struct = instance.fields[\"image\"].struct_value\n",
        "            image_struct.fields[\"bytesBase64Encoded\"].string_value = encoded_content\n",
        "\n",
        "        instances = [instance]\n",
        "        endpoint = (\n",
        "            f\"projects/{self.project}/locations/{self.location}\"\n",
        "            \"/publishers/google/models/multimodalembedding@001\"\n",
        "        )\n",
        "        response = self.client.predict(endpoint=endpoint, instances=instances)\n",
        "\n",
        "        text_embedding = None\n",
        "        if text:\n",
        "            text_emb_value = response.predictions[0][\"textEmbedding\"]\n",
        "            text_embedding = [v for v in text_emb_value]\n",
        "\n",
        "        image_embedding = None\n",
        "        if image_bytes:\n",
        "            image_emb_value = response.predictions[0][\"imageEmbedding\"]\n",
        "            image_embedding = [v for v in image_emb_value]\n",
        "\n",
        "        return EmbeddingResponse(\n",
        "            text_embedding=text_embedding, image_embedding=image_embedding\n",
        "        )"
      ],
      "metadata": {
        "id": "RWZ4p_Y-nKxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from typing import List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "from tenacity import retry, stop_after_attempt\n",
        "\n",
        "client = EmbeddingPredictionClient(project=PROJECT_ID)\n",
        "\n",
        "\n",
        "# Use a retry handler in case of failure\n",
        "@retry(reraise=True, stop=stop_after_attempt(3))\n",
        "def encode_texts_to_embeddings_with_retry(text: List[str]) -> List[List[float]]:\n",
        "    assert len(text) == 1\n",
        "\n",
        "    try:\n",
        "        return [client.get_embedding(text=text[0], image_file=None).text_embedding]\n",
        "    except Exception:\n",
        "        raise RuntimeError(\"Error getting embedding.\")\n",
        "\n",
        "\n",
        "def encode_texts_to_embeddings(text: List[str]) -> List[Optional[List[float]]]:\n",
        "    try:\n",
        "        return encode_texts_to_embeddings_with_retry(text=text)\n",
        "    except Exception:\n",
        "        return [None for _ in range(len(text))]\n",
        "\n",
        "\n",
        "@retry(reraise=True, stop=stop_after_attempt(3))\n",
        "def encode_images_to_embeddings_with_retry(image_uris: List[str]) -> List[List[float]]:\n",
        "    assert len(image_uris) == 1\n",
        "\n",
        "    try:\n",
        "        return [\n",
        "            client.get_embedding(text=None, image_file=image_uris[0]).image_embedding\n",
        "        ]\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "        raise RuntimeError(\"Error getting embedding.\")\n",
        "\n",
        "\n",
        "def encode_images_to_embeddings(image_uris: List[str]) -> List[Optional[List[float]]]:\n",
        "    try:\n",
        "        return encode_images_to_embeddings_with_retry(image_uris=image_uris)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "        return [None for _ in range(len(image_uris))]"
      ],
      "metadata": {
        "id": "5LpGjw4EnOn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from typing import Callable, Generator, List\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def generate_batches(\n",
        "    inputs: List[str], batch_size: int\n",
        ") -> Generator[List[str], None, None]:\n",
        "    \"\"\"\n",
        "    Generator function that takes a list of strings and a batch size, and yields batches of the specified size.\n",
        "    \"\"\"\n",
        "\n",
        "    for i in range(0, len(inputs), batch_size):\n",
        "        yield inputs[i : i + batch_size]\n",
        "\n",
        "\n",
        "API_IMAGES_PER_SECOND = 2\n",
        "\n",
        "\n",
        "def encode_to_embeddings_chunked(\n",
        "    process_function: Callable[[List[str]], List[Optional[List[float]]]],\n",
        "    items: List[str],\n",
        "    batch_size: int = 1,\n",
        ") -> List[Optional[List[float]]]:\n",
        "    \"\"\"\n",
        "    Function that encodes a list of strings into embeddings using a process function.\n",
        "    It takes a list of strings and returns a list of optional lists of floats.\n",
        "    The data is processed in chunks to prevent out-of-memory errors.\n",
        "    \"\"\"\n",
        "\n",
        "    embeddings_list: List[Optional[List[float]]] = []\n",
        "\n",
        "    # Prepare the batches using a generator\n",
        "    batches = generate_batches(items, batch_size)\n",
        "\n",
        "    seconds_per_job = batch_size / API_IMAGES_PER_SECOND\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for batch in tqdm(batches, total=len(items) // batch_size, position=0):\n",
        "            futures.append(executor.submit(process_function, batch))\n",
        "            time.sleep(seconds_per_job)\n",
        "\n",
        "        for future in futures:\n",
        "            embeddings_list.extend(future.result())\n",
        "    return embeddings_list"
      ],
      "metadata": {
        "id": "93tDtDsTnRjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from io import BytesIO\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# 意味検索の実施\n",
        "# 文章やキーワードをセット\n",
        "text_query = \"please teach me okinawa soul food\"\n",
        "\n",
        "# Calculate text embedding of query\n",
        "text_embedding = encode_texts_to_embeddings(text=[text_query])[0]\n",
        "\n",
        "result = data_client.search_nearest_entities(\n",
        "    request=feature_online_store_service_pb2.SearchNearestEntitiesRequest(\n",
        "        feature_view=f\"projects/{PROJECT_ID}/locations/{REGION}/featureOnlineStores/{FEATURE_ONLINE_STORE_ID}/featureViews/{FEATURE_VIEW_ID}\",\n",
        "        query=NearestNeighborQuery(\n",
        "            embedding=NearestNeighborQuery.Embedding(value=text_embedding),\n",
        "            neighbor_count=20,\n",
        "            # string_filters=[country_filter],\n",
        "        ),\n",
        "        return_full_entity=True,  # returning entities with metadata\n",
        "    )\n",
        ")\n",
        "\n",
        "selected_paths = [neighbor.entity_id for neighbor in result.nearest_neighbors.neighbors]\n",
        "distances = [neighbor.distance for neighbor in result.nearest_neighbors.neighbors]\n",
        "\n",
        "\n",
        "# Set the maximum number of images to display\n",
        "MAX_IMAGES = 20\n",
        "\n",
        "# 重複を排除しながら selected_paths と distances をペアにする\n",
        "unique_pairs = {}\n",
        "for path, distance in zip(selected_paths, distances):\n",
        "    if path not in unique_pairs:\n",
        "        unique_pairs[path] = distance\n",
        "\n",
        "# 重複が排除されたペアから、距離に基づいて並べ替え\n",
        "sorted_data = sorted(\n",
        "    unique_pairs.items(), key=lambda x: x[1], reverse=False\n",
        ")[:MAX_IMAGES]\n",
        "\n",
        "# Calculate the number of rows and columns needed to display the images\n",
        "num_cols = 4\n",
        "num_rows = math.ceil(len(sorted_data) / num_cols)\n",
        "\n",
        "\n",
        "# Create a grid of subplots to display the images\n",
        "fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(10, 12))\n",
        "\n",
        "# Loop through the top max_images images and display them in the subplots\n",
        "for i, (image_path, distance) in enumerate(sorted_data):\n",
        "    # Calculate the row and column index for the current image\n",
        "    row_idx = i // num_cols\n",
        "    col_idx = i % num_cols\n",
        "\n",
        "    # Check if image_path is a remote URL\n",
        "    if image_path.startswith(\"http://\") or image_path.startswith(\"https://\"):\n",
        "        response = requests.get(image_path)\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "    else:\n",
        "        image_path = GCS_HOST_PATH + image_path.replace(\"/content/\", \"\")\n",
        "        response = requests.get(image_path)\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "\n",
        "    # Display the image in the current subplot\n",
        "    axs[row_idx, col_idx].imshow(image, cmap=\"gray\")\n",
        "\n",
        "    # Set the title of the subplot to the image index and score\n",
        "    # axs[row_idx, col_idx].set_title(f\"Rank {i+1}, Distance = {distance:.2f}, image_path = {image_path.split('/')[-2]}\")\n",
        "    axs[row_idx, col_idx].set_title(f\"{image_path.split('/')[-2]}\")\n",
        "\n",
        "    # Remove ticks from the subplot\n",
        "    axs[row_idx, col_idx].set_xticks([])\n",
        "    axs[row_idx, col_idx].set_yticks([])\n",
        "\n",
        "# Adjust the spacing between subplots and display the plot\n",
        "plt.subplots_adjust(hspace=0.3, wspace=0.1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3_IIaZb5nUP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "al02-R2fodSC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}